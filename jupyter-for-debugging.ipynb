{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asennuskomennot.txt\t\t     requirements.txt\r\n",
      "convert_tf_checkpoint_to_pytorch.py  runs\r\n",
      "data\t\t\t\t     RUNS.log\r\n",
      "debug_notebook_in_colab.ipynb\t     run_tf_ner.py\r\n",
      "get_biobert_model.sh\t\t     s800_2\r\n",
      "get_s800_data.sh\t\t     scripts\r\n",
      "jupyter.3717719.out\t\t     slurm-barebone.sh\r\n",
      "jupyter.3726682.out\t\t     slurm-run.sh\r\n",
      "jupyter-for-debugging.ipynb\t     slurm-run-tmp.sh\r\n",
      "latest.err\t\t\t     slurm-tf-model_converter.sh\r\n",
      "latest.out\t\t\t     tasks.py\r\n",
      "launcher.sh\t\t\t     tasks.py.1\r\n",
      "logs\t\t\t\t     test.log\r\n",
      "models\t\t\t\t     utils_ner.py\r\n",
      "puhti-install.sh\t\t     utils_ner.py.1\r\n",
      "__pycache__\t\t\t     venv_transformers_ner\r\n",
      "README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/project_2001426/harttu/july-2020/transformers-ner/venv_transformers_ner/bin/python3\r\n"
     ]
    }
   ],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"intel/19.0.4\" with \"gcc/8.3.0\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hpcx-mpi/2.4.0     2) intel-mkl/2019.0.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module load gcc/8.3.0 cuda/10.1.168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt     s800_2\t\ts800SmallTrain\t s800-tools\r\n",
      "labels.txt  s800HalfTrain\ts800_tabs\t test.txt\r\n",
      "s800\t    s800-revision-data\ts800_tabs_small  train.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=\"128\"\n",
    "BERT_MODEL=\"monologg/biobert_v1.0_pubmed_pmc\"\n",
    "BERT_MODEL=\"./biobert/biobert_v1.0_pubmed_pmc\"\n",
    "BERT_MODEL=\"monologg/biobert_v1.1_pubmed\"\n",
    "BERT_MODEL=\"./models/biobertTorch/\"\n",
    "#bert_dir,\\\n",
    "#BERT_MODEL=\"./\"+bert_dir+\"/\"\n",
    "OUTPUT_DIR=\"s800_2\"\n",
    "BATCH_SIZE=\"32\"\n",
    "NUM_EPOCHS=\"1\"\n",
    "SAVE_STEPS=\"750\"\n",
    "SEED=\"1\"\n",
    "LEARNING_RATE=\"1e-5\"\n",
    "#  '--config_name', bert_model, \\\n",
    "      \n",
    "!rm -rf $OUTPUT_DIR    \n",
    "    \n",
    "argv = ['run_tf_ner.py','--data_dir','./data/s800SmallTrain/', \\\n",
    "        '--labels', './data/s800SmallTrain/labels.txt',\\\n",
    "        '--model_name_or_path', BERT_MODEL, \\\n",
    "        '--output_dir', OUTPUT_DIR, \\\n",
    "        '--max_seq_length',  MAX_LENGTH,\\\n",
    "        '--num_train_epochs', NUM_EPOCHS, \\\n",
    "        '--learning_rate', \"4e-5\", \\\n",
    "        '--per_device_train_batch_size', BATCH_SIZE,\\\n",
    "        '--save_steps', SAVE_STEPS,\\\n",
    "        '--seed', SEED,\\\n",
    "        '--learning_rate', LEARNING_RATE,\\\n",
    "        '--do_train','--do_eval','--do_predict',\n",
    "        '--overwrite_output_dir']\n",
    "\n",
    "sys.argv = argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2018 The HuggingFace Inc. team.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\" Fine-tuning the library models for named entity recognition.\"\"\"\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from importlib import import_module\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TFAutoModelForTokenClassification,\n",
    "    TFTrainer,\n",
    "    TFTrainingArguments,\n",
    ")\n",
    "from utils_ner import Split, TFTokenClassificationDataset, TokenClassificationTask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    task_type: Optional[str] = field(\n",
    "        default=\"NER\", metadata={\"help\": \"Task type to fine tune in training (e.g. NER, POS, etc)\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    use_fast: bool = field(default=False, metadata={\"help\": \"Set this flag to use fast tokenization.\"})\n",
    "    # If you want to tweak more attributes on your tokenizer, you should do it in a distinct script,\n",
    "    # or just modify its tokenizer_config.json.\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir: str = field(\n",
    "        metadata={\"help\": \"The input data dir. Should contain the .txt files for a CoNLL-2003-formatted task.\"}\n",
    "    )\n",
    "    labels: Optional[str] = field(\n",
    "        metadata={\"help\": \"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\"}\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/project_2001426/harttu/july-2020/transformers-ner/venv_transformers_ner/lib/python3.7/site-packages/transformers/training_args.py:332: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TFTrainingArguments))\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "if (\n",
    "    os.path.exists(training_args.output_dir)\n",
    "    and os.listdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    raise ValueError(\n",
    "        f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
    "    )\n",
    "\n",
    "module = import_module(\"tasks\")\n",
    "\n",
    "try:\n",
    "    token_classification_task_clazz = getattr(module, model_args.task_type)\n",
    "    token_classification_task: TokenClassificationTask = token_classification_task_clazz()\n",
    "except AttributeError:\n",
    "    raise ValueError(\n",
    "        f\"Task {model_args.task_type} needs to be defined as a TokenClassificationTask subclass in {module}. \"\n",
    "        f\"Available tasks classes are: {TokenClassificationTask.__subclasses__()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFTrainingArguments(output_dir='s800_2', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Oct20_11-14-30_r07c49.bullx', logging_first_step=False, logging_steps=500, save_steps=750, save_total_limit=None, no_cuda=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=False, tpu_name=None, xla=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    filename='test.log',\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.info(\n",
    "    \"n_replicas: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.n_replicas,\n",
    "    bool(training_args.n_replicas > 1),\n",
    "    training_args.fp16,\n",
    ")\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER - GET_LABELS\n",
      "\tUSING:./data/s800SmallTrain/labels.txt\n",
      "\t\tRETURNING:['B-Species', 'B-Strain', 'I-Species', 'I-Strain', 'O']\n",
      "LABELS:\n",
      "['B-Species', 'B-Strain', 'I-Species', 'I-Strain', 'O']\n",
      "LABEL_MAP:\n",
      "{0: 'B-Species', 1: 'B-Strain', 2: 'I-Species', 3: 'I-Strain', 4: 'O'}\n",
      "CONFIG\n",
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"do_lower_case\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-Species\",\n",
      "    \"1\": \"B-Strain\",\n",
      "    \"2\": \"I-Species\",\n",
      "    \"3\": \"I-Strain\",\n",
      "    \"4\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-Species\": 0,\n",
      "    \"B-Strain\": 1,\n",
      "    \"I-Species\": 2,\n",
      "    \"I-Strain\": 3,\n",
      "    \"O\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Prepare Token Classification task\n",
    "labels = token_classification_task.get_labels(data_args.labels)\n",
    "print(\"LABELS:\")\n",
    "print(labels)\n",
    "label_map: Dict[int, str] = {i: label for i, label in enumerate(labels)}\n",
    "print(\"LABEL_MAP:\")\n",
    "print(label_map)\n",
    "num_labels = len(labels)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "#\n",
    "# Distributed training:\n",
    "# The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab.\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    id2label=label_map,\n",
    "    label2id={label: i for i, label in enumerate(labels)},\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "print(\"CONFIG\")\n",
    "print(config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=model_args.use_fast,\n",
    ")\n",
    "#'monologg/biobert_v1.1_pubmed',#\n",
    "with training_args.strategy.scope():\n",
    "    model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        from_pt=True,#bool(\".bin\" in model_args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETTING DATASETS\n"
     ]
    }
   ],
   "source": [
    "print(\"SETTING DATASETS\")\n",
    "# Get datasets\n",
    "train_dataset = (\n",
    "    TFTokenClassificationDataset(\n",
    "        token_classification_task=token_classification_task,\n",
    "        data_dir=data_args.data_dir,\n",
    "        tokenizer=tokenizer,\n",
    "        labels=labels,\n",
    "        model_type=config.model_type,\n",
    "        max_seq_length=data_args.max_seq_length,\n",
    "        overwrite_cache=data_args.overwrite_cache,\n",
    "        mode=Split.train,\n",
    "    )\n",
    "    if training_args.do_train\n",
    "    else None\n",
    ")\n",
    "eval_dataset = (\n",
    "    TFTokenClassificationDataset(\n",
    "        token_classification_task=token_classification_task,\n",
    "        data_dir=data_args.data_dir,\n",
    "        tokenizer=tokenizer,\n",
    "        labels=labels,\n",
    "        model_type=config.model_type,\n",
    "        max_seq_length=data_args.max_seq_length,\n",
    "        overwrite_cache=data_args.overwrite_cache,\n",
    "        mode=Split.dev,\n",
    "    )\n",
    "    if training_args.do_eval\n",
    "    else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def align_predictions(predictions: np.ndarray, label_ids: np.ndarray) -> Tuple[List[int], List[int]]:\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    out_label_list = [[] for _ in range(batch_size)]\n",
    "    preds_list = [[] for _ in range(batch_size)]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            if label_ids[i, j] != -100:\n",
    "                out_label_list[i].append(label_map[label_ids[i][j]])\n",
    "                preds_list[i].append(label_map[preds[i][j]])\n",
    "    #print(\"ALIGN_PREDICTIONS:\"+str(len(out_label_list)))\n",
    "    return preds_list, out_label_list\n",
    "\n",
    "def compute_metrics(p: EvalPrediction) -> Dict:\n",
    "    preds_list, out_label_list = align_predictions(p.predictions, p.label_ids)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(out_label_list, preds_list),\n",
    "        \"recall\": recall_score(out_label_list, preds_list),\n",
    "        \"f1\": f1_score(out_label_list, preds_list),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asennuskomennot.txt\t\t     README.md\r\n",
      "convert_tf_checkpoint_to_pytorch.py  requirements.txt\r\n",
      "data\t\t\t\t     runs\r\n",
      "debug_notebook_in_colab.ipynb\t     RUNS.log\r\n",
      "get_biobert_model.sh\t\t     run_tf_ner.py\r\n",
      "get_s800_data.sh\t\t     scripts\r\n",
      "jupyter.3717719.out\t\t     slurm-barebone.sh\r\n",
      "jupyter.3726682.out\t\t     slurm-run.sh\r\n",
      "jupyter-for-debugging.ipynb\t     slurm-run-tmp.sh\r\n",
      "latest.err\t\t\t     slurm-tf-model_converter.sh\r\n",
      "latest.out\t\t\t     tasks.py\r\n",
      "launcher.sh\t\t\t     tasks.py.1\r\n",
      "logs\t\t\t\t     test.log\r\n",
      "models\t\t\t\t     utils_ner.py\r\n",
      "puhti-install.sh\t\t     utils_ner.py.1\r\n",
      "__pycache__\t\t\t     venv_transformers_ner\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFTrainingArguments(output_dir='s800_2', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Oct20_11-14-30_r07c49.bullx', logging_first_step=False, logging_steps=500, save_steps=750, save_total_limit=None, no_cuda=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=False, tpu_name=None, xla=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING TRAINER\n"
     ]
    }
   ],
   "source": [
    "print(\"INITIALIZING TRAINER\")\n",
    "initial_learning_rate=0.001\n",
    "decay_steps=10000\n",
    "# Initialize our Trainer\n",
    "trainer = TFTrainer(\n",
    "    model=model,\n",
    "    #optimizer=(tf.keras.optimizers.SGD(\n",
    "    #              learning_rate=learning_rate_fn),None),\n",
    "    #optimizers=(tf.keras.optimizers.Adam(\n",
    "    #learning_rate=initial_learning_rate, beta_1=0.9, \n",
    "    #beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    #name='Adam'),tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    #initial_learning_rate, decay_steps, \n",
    "    #end_learning_rate=0.0001, power=1.0,\n",
    "    #cycle=False, name=None\n",
    "    #)),\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset.get_dataset() if train_dataset else None,\n",
    "    eval_dataset=eval_dataset.get_dataset() if eval_dataset else None,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <transformers.modeling_tf_bert.TFBertForTokenClassification at 0x7f9dc7d03320>,\n",
       " 'args': TFTrainingArguments(output_dir='s800_2', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Oct20_11-14-30_r07c49.bullx', logging_first_step=False, logging_steps=500, save_steps=750, save_total_limit=None, no_cuda=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=None, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=False, tpu_name=None, xla=False),\n",
       " 'train_dataset': <_AssertCardinalityDataset shapes: ({input_ids: (None,), attention_mask: (None,), token_type_ids: (None,)}, (None,)), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>,\n",
       " 'eval_dataset': <_AssertCardinalityDataset shapes: ({input_ids: (None,), attention_mask: (None,), token_type_ids: (None,)}, (None,)), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>,\n",
       " 'compute_metrics': <function __main__.compute_metrics(p: transformers.trainer_utils.EvalPrediction) -> Dict>,\n",
       " 'optimizer': None,\n",
       " 'lr_scheduler': None,\n",
       " 'gradient_accumulator': <transformers.optimization_tf.GradientAccumulator at 0x7fa0b1b10940>,\n",
       " 'global_step': 0,\n",
       " 'epoch_logging': 0,\n",
       " 'tb_writer': <tensorflow.python.ops.summary_ops_v2.ResourceSummaryWriter at 0x7f9cad86df28>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      " 1/35 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/project_2001426/harttu/july-2020/transformers-ner/venv_transformers_ner/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:493: UserWarning: Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/35 [======>.......................] - ETA: 9:22"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"TRAINING\")\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    tokenizer.save_pretrained(training_args.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"EVALUATING\")\n",
    "# Evaluation\n",
    "results = {}\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "    result = trainer.evaluate()\n",
    "    output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\n",
    "\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "\n",
    "        for key, value in result.items():\n",
    "            logger.info(\"  %s = %s\", key, value)\n",
    "            writer.write(\"%s = %s\\n\" % (key, value))\n",
    "\n",
    "        results.update(result)\n",
    "\n",
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"PREDICTING\")\n",
    "if training_args.do_predict:\n",
    "    test_dataset = TFTokenClassificationDataset(\n",
    "        token_classification_task=token_classification_task,\n",
    "        data_dir=data_args.data_dir,\n",
    "        tokenizer=tokenizer,\n",
    "        labels=labels,\n",
    "        model_type=config.model_type,\n",
    "        max_seq_length=data_args.max_seq_length,\n",
    "        overwrite_cache=data_args.overwrite_cache,\n",
    "        mode=Split.test,\n",
    "    )\n",
    "\n",
    "    predictions, label_ids, metrics = trainer.predict(test_dataset.get_dataset())\n",
    "    preds_list, labels_list = align_predictions(predictions, label_ids)\n",
    "    report = classification_report(labels_list, preds_list)\n",
    "\n",
    "    logger.info(\"\\n%s\", report)\n",
    "\n",
    "    output_test_results_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n",
    "\n",
    "    with open(output_test_results_file, \"w\") as writer:\n",
    "        writer.write(\"%s\\n\" % report)\n",
    "\n",
    "    # Save predictions\n",
    "    output_test_predictions_file = os.path.join(training_args.output_dir, \"test_predictions.txt\")\n",
    "\n",
    "    with open(output_test_predictions_file, \"w\") as writer:\n",
    "        with open(os.path.join(data_args.data_dir, \"test.txt\"), \"r\") as f:\n",
    "            example_id = 0\n",
    "\n",
    "            for line in f:\n",
    "                if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
    "                    writer.write(line)\n",
    "\n",
    "                    if not preds_list[example_id]:\n",
    "                        example_id += 1\n",
    "                elif preds_list[example_id]:\n",
    "                    output_line = line.split()[0] + \" \" + preds_list[example_id].pop(0) + \"\\n\"\n",
    "\n",
    "                    writer.write(output_line)\n",
    "                else:\n",
    "                    logger.warning(\"Maximum sequence length exceeded: No prediction for '%s'.\", line.split()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = os.path.join(data_args.data_dir, \"test.txt\")\n",
    "!head -20 $tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = os.path.join(training_args.output_dir, \"test_predictions.txt\")\n",
    "!head -20 $tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_transformers_ner",
   "language": "python",
   "name": "venv_transformers_ner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
