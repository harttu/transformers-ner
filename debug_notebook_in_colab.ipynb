{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "debug_notebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCFE-_1hHD8z",
        "outputId": "abe9e0ef-5910-4e8c-de27-f488789ada4a"
      },
      "source": [
        "!module load gcc/8.3.0 cuda/10.1.168"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "The following have been reloaded with a version change:\r\n",
            "  1) gcc/7.4.0 => gcc/8.3.0\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHBHYGbNHD9H",
        "outputId": "cd7a30ae-5027-4820-c93d-f53750727181"
      },
      "source": [
        "!module list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?1h\u001b=\r\u001b[m\r\n",
            "Currently Loaded Modules:\u001b[m\r\n",
            "  1) gcc/7.4.0   2) python-data/3.7.3-1\u001b[m\r\n",
            "\u001b[m\r\n",
            " \u001b[m\r\n",
            "\u001b[m\r\n",
            "\r\u001b[K\u001b[?1l\u001b>"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvoNmD2THLPp",
        "outputId": "fbb3b6e6-646e-4744-f356-eb4a888d1221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/harttu/transformers-ner/master/tasks.py\n",
        "!wget https://raw.githubusercontent.com/harttu/transformers-ner/master/utils_ner.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-01 07:44:30--  https://raw.githubusercontent.com/harttu/transformers-ner/master/tasks.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5509 (5.4K) [text/plain]\n",
            "Saving to: ‘tasks.py’\n",
            "\n",
            "tasks.py            100%[===================>]   5.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-01 07:44:30 (57.7 MB/s) - ‘tasks.py’ saved [5509/5509]\n",
            "\n",
            "--2020-10-01 07:44:30--  https://raw.githubusercontent.com/harttu/transformers-ner/master/utils_ner.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15629 (15K) [text/plain]\n",
            "Saving to: ‘utils_ner.py’\n",
            "\n",
            "utils_ner.py        100%[===================>]  15.26K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-10-01 07:44:31 (1.23 MB/s) - ‘utils_ner.py’ saved [15629/15629]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58DUeS-0HLfY",
        "outputId": "620f7de4-fd70-407b-9589-fa3e382fe930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "!pip install seqeval transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 17.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 20.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4f350c6e8b68e098704f45f3ac7c77f8800821f3161f3cc2d090d379f5e37980\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LpZhWVpHD9X"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from importlib import import_module\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    EvalPrediction,\n",
        "    HfArgumentParser,\n",
        "    TFAutoModelForTokenClassification,\n",
        "    TFTrainer,\n",
        "    TFTrainingArguments,\n",
        ")\n",
        "from utils_ner import Split, TFTokenClassificationDataset, TokenClassificationTask\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0-_QLJKJZAE"
      },
      "source": [
        "MAX_LENGTH=128\n",
        "BERT_MODEL=bert-base-multilingual-cased\n",
        "\n",
        "OUTPUT_DIR=germeval-model\n",
        "BATCH_SIZE=32\n",
        "NUM_EPOCHS=3\n",
        "SAVE_STEPS=750\n",
        "SEED=1\n",
        "\n",
        "python3 run_tf_ner.py --data_dir ./data/ \\\n",
        "--labels ./data/labels.txt \\\n",
        "--model_name_or_path $BERT_MODEL \\\n",
        "--output_dir $OUTPUT_DIR \\\n",
        "--max_seq_length  $MAX_LENGTH \\\n",
        "--num_train_epochs $NUM_EPOCHS \\\n",
        "--per_device_train_batch_size $BATCH_SIZE \\\n",
        "--save_steps $SAVE_STEPS \\\n",
        "--seed $SEED \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--do_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXXmmUEUIPDs"
      },
      "source": [
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name_or_path: str = field(\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "    )\n",
        "    config_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
        "    )\n",
        "    task_type: Optional[str] = field(\n",
        "        default=\"NER\", metadata={\"help\": \"Task type to fine tune in training (e.g. NER, POS, etc)\"}\n",
        "    )\n",
        "    tokenizer_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
        "    )\n",
        "    use_fast: bool = field(default=False, metadata={\"help\": \"Set this flag to use fast tokenization.\"})\n",
        "    # If you want to tweak more attributes on your tokenizer, you should do it in a distinct script,\n",
        "    # or just modify its tokenizer_config.json.\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    data_dir: str = field(\n",
        "        metadata={\"help\": \"The input data dir. Should contain the .txt files for a CoNLL-2003-formatted task.\"}\n",
        "    )\n",
        "    labels: Optional[str] = field(\n",
        "        metadata={\"help\": \"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\"}\n",
        "    )\n",
        "    max_seq_length: int = field(\n",
        "        default=128,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded.\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
        "    )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ96AgMRLGVJ"
      },
      "source": [
        "MAX_LENGTH=\"128\"\n",
        "BERT_MODEL=\"bert-base-multilingual-cased\"\n",
        "\n",
        "OUTPUT_DIR=\"germeval-model\"\n",
        "BATCH_SIZE=\"32\"\n",
        "NUM_EPOCHS=\"32\"\n",
        "SAVE_STEPS=\"750\"\n",
        "SEED=\"1\"\n",
        "\n",
        "argv = ['run_tf_ner.py','--data_dir','./data/', \\\n",
        "        '--labels', '/data/labels.txt',\\\n",
        "        '--model_name_or_path', BERT_MODEL,\\\n",
        "        '--output_dir', OUTPUT_DIR, \\\n",
        "        '--max_seq_length',  MAX_LENGTH,\\\n",
        "        '--num_train_epochs', NUM_EPOCHS, \\\n",
        "        '--per_device_train_batch_size', BATCH_SIZE,\\\n",
        "        '--save_steps', SAVE_STEPS,\\\n",
        "        '--seed', SEED,\\\n",
        "        '--do_train','--do_eval','--do_predict']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtsMe9rjMh3t",
        "outputId": "36c5e29e-4268-40b2-b6d2-9652e95b7ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import sys\n",
        "print(sys.argv)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['run_tf_ner.py', '--data_dir', './data/', '--labels', '/data/labels.txt', '--model_name_or_path', 'bert-base-multilingual-cased', '--output_dir', 'germeval-model', '--max_seq_length', 128, '--num_train_epochs', 3, '--per_device_train_batch_size', 32, '--save_steps', 750, '--seed', 1, '--do_train', '--do_eval', '--do_predict']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UM4uPTzNE_s"
      },
      "source": [
        "sys.argv = argv"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "409T0wejOHGA",
        "outputId": "b8a73dcd-1b6a-446e-dc03-206300dffc74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# See all possible arguments in src/transformers/training_args.py\n",
        "# or by passing the --help flag to this script.\n",
        "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
        "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TFTrainingArguments))\n",
        "model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
        "\n",
        "print(dir(model_args))\n",
        "    \n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'cache_dir', 'config_name', 'model_name_or_path', 'task_type', 'tokenizer_name', 'use_fast']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/training_args.py:332: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvz6-XMaHD96",
        "outputId": "ba7271ff-2bcd-410d-eabb-c6e39d514adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "def main():\n",
        "    # See all possible arguments in src/transformers/training_args.py\n",
        "    # or by passing the --help flag to this script.\n",
        "    # We now keep distinct sets of args, for a cleaner separation of concerns.\n",
        "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TFTrainingArguments))\n",
        "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
        "\n",
        "    print(dir(model_args))\n",
        "    \n",
        "\n",
        "    if (\n",
        "        os.path.exists(training_args.output_dir)\n",
        "        and os.listdir(training_args.output_dir)\n",
        "        and training_args.do_train\n",
        "        and not training_args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
        "        )\n",
        "\n",
        "    module = import_module(\"tasks\")\n",
        "\n",
        "    try:\n",
        "        token_classification_task_clazz = getattr(module, model_args.task_type)\n",
        "        token_classification_task: TokenClassificationTask = token_classification_task_clazz()\n",
        "    except AttributeError:\n",
        "        raise ValueError(\n",
        "            f\"Task {model_args.task_type} needs to be defined as a TokenClassificationTask subclass in {module}. \"\n",
        "            f\"Available tasks classes are: {TokenClassificationTask.__subclasses__()}\"\n",
        "        )\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "    logger.info(\n",
        "        \"n_replicas: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        training_args.n_replicas,\n",
        "        bool(training_args.n_replicas > 1),\n",
        "        training_args.fp16,\n",
        "    )\n",
        "    logger.info(\"Training/evaluation parameters %s\", training_args)\n",
        "\n",
        "    # Prepare Token Classification task\n",
        "    labels = token_classification_task.get_labels(data_args.labels)\n",
        "    label_map: Dict[int, str] = {i: label for i, label in enumerate(labels)}\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    #\n",
        "    # Distributed training:\n",
        "    # The .from_pretrained methods guarantee that only one local process can concurrently\n",
        "    # download model & vocab.\n",
        "\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "        num_labels=num_labels,\n",
        "        id2label=label_map,\n",
        "        label2id={label: i for i, label in enumerate(labels)},\n",
        "        cache_dir=model_args.cache_dir,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "        use_fast=model_args.use_fast,\n",
        "    )\n",
        "\n",
        "    with training_args.strategy.scope():\n",
        "        model = TFAutoModelForTokenClassification.from_pretrained(\n",
        "            model_args.model_name_or_path,\n",
        "            from_pt=bool(\".bin\" in model_args.model_name_or_path),\n",
        "            config=config,\n",
        "            cache_dir=model_args.cache_dir,\n",
        "        )\n",
        "\n",
        "    # Get datasets\n",
        "    train_dataset = (\n",
        "        TFTokenClassificationDataset(\n",
        "            token_classification_task=token_classification_task,\n",
        "            data_dir=data_args.data_dir,\n",
        "            tokenizer=tokenizer,\n",
        "            labels=labels,\n",
        "            model_type=config.model_type,\n",
        "            max_seq_length=data_args.max_seq_length,\n",
        "            overwrite_cache=data_args.overwrite_cache,\n",
        "            mode=Split.train,\n",
        "        )\n",
        "        if training_args.do_train\n",
        "        else None\n",
        "    )\n",
        "    eval_dataset = (\n",
        "        TFTokenClassificationDataset(\n",
        "            token_classification_task=token_classification_task,\n",
        "            data_dir=data_args.data_dir,\n",
        "            tokenizer=tokenizer,\n",
        "            labels=labels,\n",
        "            model_type=config.model_type,\n",
        "            max_seq_length=data_args.max_seq_length,\n",
        "            overwrite_cache=data_args.overwrite_cache,\n",
        "            mode=Split.dev,\n",
        "        )\n",
        "        if training_args.do_eval\n",
        "        else None\n",
        "    )\n",
        "\n",
        "    def align_predictions(predictions: np.ndarray, label_ids: np.ndarray) -> Tuple[List[int], List[int]]:\n",
        "        preds = np.argmax(predictions, axis=2)\n",
        "        batch_size, seq_len = preds.shape\n",
        "        out_label_list = [[] for _ in range(batch_size)]\n",
        "        preds_list = [[] for _ in range(batch_size)]\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for j in range(seq_len):\n",
        "                if label_ids[i, j] != -100:\n",
        "                    out_label_list[i].append(label_map[label_ids[i][j]])\n",
        "                    preds_list[i].append(label_map[preds[i][j]])\n",
        "\n",
        "        return preds_list, out_label_list\n",
        "\n",
        "    def compute_metrics(p: EvalPrediction) -> Dict:\n",
        "        preds_list, out_label_list = align_predictions(p.predictions, p.label_ids)\n",
        "\n",
        "        return {\n",
        "            \"precision\": precision_score(out_label_list, preds_list),\n",
        "            \"recall\": recall_score(out_label_list, preds_list),\n",
        "            \"f1\": f1_score(out_label_list, preds_list),\n",
        "        }\n",
        "\n",
        "    # Initialize our Trainer\n",
        "    trainer = TFTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset.get_dataset() if train_dataset else None,\n",
        "        eval_dataset=eval_dataset.get_dataset() if eval_dataset else None,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    if training_args.do_train:\n",
        "        trainer.train()\n",
        "        trainer.save_model()\n",
        "        tokenizer.save_pretrained(training_args.output_dir)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if training_args.do_eval:\n",
        "        logger.info(\"*** Evaluate ***\")\n",
        "\n",
        "        result = trainer.evaluate()\n",
        "        output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\n",
        "\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            logger.info(\"***** Eval results *****\")\n",
        "\n",
        "            for key, value in result.items():\n",
        "                logger.info(\"  %s = %s\", key, value)\n",
        "                writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "            results.update(result)\n",
        "\n",
        "    # Predict\n",
        "    if training_args.do_predict:\n",
        "        test_dataset = TFTokenClassificationDataset(\n",
        "            token_classification_task=token_classification_task,\n",
        "            data_dir=data_args.data_dir,\n",
        "            tokenizer=tokenizer,\n",
        "            labels=labels,\n",
        "            model_type=config.model_type,\n",
        "            max_seq_length=data_args.max_seq_length,\n",
        "            overwrite_cache=data_args.overwrite_cache,\n",
        "            mode=Split.test,\n",
        "        )\n",
        "\n",
        "        predictions, label_ids, metrics = trainer.predict(test_dataset.get_dataset())\n",
        "        preds_list, labels_list = align_predictions(predictions, label_ids)\n",
        "        report = classification_report(labels_list, preds_list)\n",
        "\n",
        "        logger.info(\"\\n%s\", report)\n",
        "\n",
        "        output_test_results_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n",
        "\n",
        "        with open(output_test_results_file, \"w\") as writer:\n",
        "            writer.write(\"%s\\n\" % report)\n",
        "\n",
        "        # Save predictions\n",
        "        output_test_predictions_file = os.path.join(training_args.output_dir, \"test_predictions.txt\")\n",
        "\n",
        "        with open(output_test_predictions_file, \"w\") as writer:\n",
        "            with open(os.path.join(data_args.data_dir, \"test.txt\"), \"r\") as f:\n",
        "                example_id = 0\n",
        "\n",
        "                for line in f:\n",
        "                    if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
        "                        writer.write(line)\n",
        "\n",
        "                        if not preds_list[example_id]:\n",
        "                            example_id += 1\n",
        "                    elif preds_list[example_id]:\n",
        "                        output_line = line.split()[0] + \" \" + preds_list[example_id].pop(0) + \"\\n\"\n",
        "\n",
        "                        writer.write(output_line)\n",
        "                    else:\n",
        "                        logger.warning(\"Maximum sequence length exceeded: No prediction for '%s'.\", line.split()[0])\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: run_tf_ner.py [-h] --model_name_or_path MODEL_NAME_OR_PATH\n",
            "                     [--config_name CONFIG_NAME] [--task_type TASK_TYPE]\n",
            "                     [--tokenizer_name TOKENIZER_NAME] [--use_fast]\n",
            "                     [--cache_dir CACHE_DIR] --data_dir DATA_DIR --labels\n",
            "                     LABELS [--max_seq_length MAX_SEQ_LENGTH]\n",
            "                     [--overwrite_cache] --output_dir OUTPUT_DIR\n",
            "                     [--overwrite_output_dir] [--do_train] [--do_eval]\n",
            "                     [--do_predict] [--evaluate_during_training]\n",
            "                     [--evaluation_strategy {EvaluationStrategy.NO,EvaluationStrategy.STEPS,EvaluationStrategy.EPOCH}]\n",
            "                     [--prediction_loss_only]\n",
            "                     [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                     [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                     [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
            "                     [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
            "                     [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                     [--learning_rate LEARNING_RATE]\n",
            "                     [--weight_decay WEIGHT_DECAY] [--adam_beta1 ADAM_BETA1]\n",
            "                     [--adam_beta2 ADAM_BETA2] [--adam_epsilon ADAM_EPSILON]\n",
            "                     [--max_grad_norm MAX_GRAD_NORM]\n",
            "                     [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                     [--max_steps MAX_STEPS] [--warmup_steps WARMUP_STEPS]\n",
            "                     [--logging_dir LOGGING_DIR] [--logging_first_step]\n",
            "                     [--logging_steps LOGGING_STEPS] [--save_steps SAVE_STEPS]\n",
            "                     [--save_total_limit SAVE_TOTAL_LIMIT] [--no_cuda]\n",
            "                     [--seed SEED] [--fp16] [--fp16_opt_level FP16_OPT_LEVEL]\n",
            "                     [--local_rank LOCAL_RANK] [--tpu_num_cores TPU_NUM_CORES]\n",
            "                     [--tpu_metrics_debug] [--debug] [--dataloader_drop_last]\n",
            "                     [--eval_steps EVAL_STEPS]\n",
            "                     [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "                     [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
            "                     [--disable_tqdm] [--no-remove_unused_columns]\n",
            "                     [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
            "                     [--load_best_model_at_end]\n",
            "                     [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
            "                     [--greater_is_better] [--tpu_name TPU_NAME] [--xla]\n",
            "run_tf_ner.py: error: argument --max_seq_length: invalid int value: '$MAX_LENGTH'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_cc-ZP1HD-G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIk0SSmXHD-R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbZb66yAHD-k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MgZ3y2uHD-y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qkY2TrsHD--"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGrI_xpRHD_J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}